{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bb6fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a82f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the datasets\n",
    "question = pd.read_csv(r'C:\\\\Users\\\\kfps86\\\\Downloads\\\\dataset\\\\question_metadata.csv')\n",
    "answers = pd.read_csv(r'C:\\\\Users\\\\kfps86\\\\Downloads\\\\dataset\\\\answers_metadata.csv')\n",
    "student = pd.read_csv(r'C:\\\\Users\\\\kfps86\\\\Downloads\\\\dataset\\\\student_metadata.csv')\n",
    "subject = pd.read_csv(r'C:\\\\Users\\\\kfps86\\\\Downloads\\\\dataset\\\\subject_metadata.csv')\n",
    "training = pd.read_csv(r'C:\\\\Users\\\\kfps86\\\\Downloads\\\\dataset\\\\training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5a71c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a test_train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# np.random.seed(42)\n",
    "train_set, test_set = train_test_split(training, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "198ff3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = answers.dropna(subset=['AnswerId']) \n",
    "# 7 values in AnswerId are na (out of 19834820), hence we are droppping those 7 values\n",
    "answers['AnswerId'] = answers['AnswerId'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60a39e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the datasets\n",
    "train_set = train_set.merge(answers , how='inner', on='AnswerId')\n",
    "train_set = train_set.merge(student, how='inner', on='UserId')\n",
    "train_set = train_set.merge(question, how='inner', on='QuestionId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0def1158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop nans\n",
    "train_set.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e334a791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>AnswerId</th>\n",
       "      <th>IsCorrect</th>\n",
       "      <th>CorrectAnswer</th>\n",
       "      <th>AnswerValue</th>\n",
       "      <th>DateAnswered</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Gender</th>\n",
       "      <th>DateOfBirth</th>\n",
       "      <th>PremiumPupil</th>\n",
       "      <th>SubjectId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27185</td>\n",
       "      <td>40527</td>\n",
       "      <td>10797164</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-18 22:03:00.000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-09-01 00:00:00.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3, 49, 61, 171]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>27185</td>\n",
       "      <td>102085</td>\n",
       "      <td>11623933</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-21 20:08:00.000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2005-09-01 00:00:00.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3, 49, 61, 171]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>27185</td>\n",
       "      <td>86279</td>\n",
       "      <td>11606301</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-02-09 12:45:00.000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2004-07-01 00:00:00.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3, 49, 61, 171]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27185</td>\n",
       "      <td>55310</td>\n",
       "      <td>15582540</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-22 18:45:00.000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2003-09-01 00:00:00.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3, 49, 61, 171]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>27185</td>\n",
       "      <td>34815</td>\n",
       "      <td>7797864</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-20 18:28:00.000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006-02-01 00:00:00.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3, 49, 61, 171]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    QuestionId  UserId  AnswerId  IsCorrect  CorrectAnswer  AnswerValue  \\\n",
       "6        27185   40527  10797164          1              1            1   \n",
       "20       27185  102085  11623933          1              1            1   \n",
       "24       27185   86279  11606301          0              1            2   \n",
       "26       27185   55310  15582540          1              1            1   \n",
       "33       27185   34815   7797864          1              1            1   \n",
       "\n",
       "               DateAnswered  Confidence  Gender              DateOfBirth  \\\n",
       "6   2019-03-18 22:03:00.000       100.0       1  2004-09-01 00:00:00.000   \n",
       "20  2019-11-21 20:08:00.000        50.0       1  2005-09-01 00:00:00.000   \n",
       "24  2019-02-09 12:45:00.000        50.0       2  2004-07-01 00:00:00.000   \n",
       "26  2019-04-22 18:45:00.000       100.0       2  2003-09-01 00:00:00.000   \n",
       "33  2019-11-20 18:28:00.000       100.0       2  2006-02-01 00:00:00.000   \n",
       "\n",
       "    PremiumPupil         SubjectId  \n",
       "6            0.0  [3, 49, 61, 171]  \n",
       "20           0.0  [3, 49, 61, 171]  \n",
       "24           1.0  [3, 49, 61, 171]  \n",
       "26           0.0  [3, 49, 61, 171]  \n",
       "33           0.0  [3, 49, 61, 171]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "879a1934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "# need to change DateAnswered and DateOfBirth columns to datetime format\n",
    "train_set['DateAnswered'] = pd.to_datetime(train_set['DateAnswered'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "train_set['DateOfBirth'] = pd.to_datetime(train_set['DateOfBirth'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "# change SubjectId to list format\n",
    "train_set['SubjectId'] = train_set['SubjectId'].str.strip('[]').str.split(',')\n",
    "\n",
    "# https://stackoverflow.com/questions/45312377/how-to-one-hot-encode-from-a-pandas-column-containing-a-list\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# create a one hot encoding column for each category\n",
    "# uses up a lot of RAM though\n",
    "mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "\n",
    "train_set = train_set.join(\n",
    "            pd.DataFrame.sparse.from_spmatrix(\n",
    "                mlb.fit_transform(train_set.pop('SubjectId')),\n",
    "                index=train_set.index,\n",
    "                columns=mlb.classes_))\n",
    "\n",
    "# train_set['DateAnswered'] = train_set['DateAnswered'].values.astype('float')\n",
    "# train_set['DateOfBirth'] = train_set['DateOfBirth'].values.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16126370",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-d2c21bca1d9d>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['total_answered'] = train_set.groupby(['UserId'])['IsCorrect'].transform('count')\n",
      "<ipython-input-25-d2c21bca1d9d>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['total_correct'] = train_set.groupby(['UserId'])['IsCorrect'].transform('sum')\n",
      "<ipython-input-25-d2c21bca1d9d>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['prop_correct'] = train_set['total_correct'] / train_set['total_answered']\n",
      "<ipython-input-25-d2c21bca1d9d>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['CMA'] = CMA.reset_index(level=0, drop=True)\n",
      "<ipython-input-25-d2c21bca1d9d>:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['total_q_answered'] = train_set.groupby(['QuestionId'])['QuestionId'].transform('count')\n",
      "<ipython-input-25-d2c21bca1d9d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['lvl2'] = 0\n",
      "<ipython-input-25-d2c21bca1d9d>:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['CMA_correct_subject'] = CMA_correct_subject.reset_index(level=[0,1], drop=True)\n",
      "<ipython-input-25-d2c21bca1d9d>:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['holiday'] = 1\n",
      "<ipython-input-25-d2c21bca1d9d>:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['help'] = 0\n",
      "<ipython-input-25-d2c21bca1d9d>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['yr2'] = 1\n",
      "<ipython-input-25-d2c21bca1d9d>:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['age'] = train_set['DateAnswered'] - train_set['DateOfBirth']\n",
      "<ipython-input-25-d2c21bca1d9d>:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['term'] = 6\n",
      "<ipython-input-25-d2c21bca1d9d>:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['time'] = 4\n",
      "<ipython-input-25-d2c21bca1d9d>:111: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['is_weekend'] = 0\n",
      "<ipython-input-25-d2c21bca1d9d>:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['last_answered'] = train_set['DateAnswered'] - datetime.datetime.strptime('2018-09-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
      "<ipython-input-25-d2c21bca1d9d>:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['repeat'] = (train_set['UserId']==train_set['UserId'].shift(1))\n"
     ]
    }
   ],
   "source": [
    "# based on: https://github.com/ageron/handson-ml2/blob/master/02_end_to_end_machine_learning_project.ipynb\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self): # no *args or **kargs\n",
    "    def fit(self, train_set, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, train_set):\n",
    "        \n",
    "        # cat => numerical value # 'total_answered',\n",
    "        train_set['total_answered'] = train_set.groupby(['UserId'])['IsCorrect'].transform('count')\n",
    "\n",
    "        # cat => numerical value # 'prop_correct',\n",
    "        train_set['total_correct'] = train_set.groupby(['UserId'])['IsCorrect'].transform('sum')\n",
    "        train_set['prop_correct'] = train_set['total_correct'] / train_set['total_answered']\n",
    "#         train_set.drop('total_correct', inplace=True)\n",
    "\n",
    "        # cat / numerical => numerical valueCMA\n",
    "        train_set.sort_values(['UserId', 'DateAnswered'], inplace=True)\n",
    "        CMA = train_set.groupby(['UserId']).IsCorrect.expanding().mean()\n",
    "        train_set['CMA'] = CMA.reset_index(level=0, drop=True)\n",
    "\n",
    "        # 'total_q_answered',\n",
    "        train_set['total_q_answered'] = train_set.groupby(['QuestionId'])['QuestionId'].transform('count')\n",
    "\n",
    "        # lvl2 - needs SubjectId first\n",
    "        train_set['lvl2'] = 0\n",
    "        for i in [' 101', ' 1156', ' 119', ' 149', ' 151', ' 32', ' 49', ' 692', ' 71']:\n",
    "            if i in train_set.columns.tolist():\n",
    "                i_int = (int(i[1:]))\n",
    "                train_set['lvl2'] = train_set['lvl2'] + (train_set[i] * i_int)\n",
    "\n",
    "        # CMA_correct_subject - need lvl2 first\n",
    "        CMA_correct_subject = train_set.groupby(['UserId', 'lvl2']).IsCorrect.expanding().mean()\n",
    "        train_set['CMA_correct_subject'] = CMA_correct_subject.reset_index(level=[0,1], drop=True)\n",
    "\n",
    "        # 'holiday',\n",
    "        train_set['holiday'] = 1\n",
    "        train_set.loc[((train_set['DateAnswered'] < '2018-10-20') & (train_set['DateAnswered'] > '2018-09-03')) |\n",
    "              ((train_set['DateAnswered'] > '2018-10-28') & (train_set['DateAnswered'] < '2018-12-20')) |\n",
    "              ((train_set['DateAnswered'] > '2019-01-02') & (train_set['DateAnswered'] < '2019-02-16')) |\n",
    "              ((train_set['DateAnswered'] > '2019-02-24') & (train_set['DateAnswered'] < '2019-04-06')) |\n",
    "              ((train_set['DateAnswered'] > '2019-04-22') & (train_set['DateAnswered'] < '2019-05-25')) |\n",
    "              ((train_set['DateAnswered'] > '2019-06-02') & (train_set['DateAnswered'] < '2019-07-25')) |\n",
    "\n",
    "              ((train_set['DateAnswered'] > '2019-09-01') & (train_set['DateAnswered'] < '2019-10-19')) |\n",
    "              ((train_set['DateAnswered'] > '2019-10-27') & (train_set['DateAnswered'] < '2019-12-20')) |\n",
    "              ((train_set['DateAnswered'] > '2020-01-05') & (train_set['DateAnswered'] < '2020-02-15')) |\n",
    "              ((train_set['DateAnswered'] > '2020-02-23') & (train_set['DateAnswered'] < '2020-04-03')) |\n",
    "              ((train_set['DateAnswered'] > '2020-04-19') & (train_set['DateAnswered'] < '2020-05-23')) |\n",
    "              ((train_set['DateAnswered'] > '2020-05-31') & (train_set['DateAnswered'] < '2020-07-23')) \n",
    "              ,'holiday'] = 0\n",
    "\n",
    "        train_set['help'] = 0\n",
    "        \n",
    "        # 'unique_day',\n",
    "        unique_student_train = pd.DataFrame(data=train_set['UserId'].unique(), columns=['UserId'])\n",
    "        unique_student_train['unique_day'] = 0\n",
    "        for i in range(len(unique_student_train)):\n",
    "                unique_student_train.iloc[i, 1] =  len(train_set.loc[train_set['UserId']==unique_student_train.iloc[i, 0]]['DateAnswered'].dt.normalize().unique())\n",
    "        train_set = train_set.merge(unique_student_train, how='inner', on='UserId')\n",
    "        del unique_student_train\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "        # 'yr2',\n",
    "        train_set['yr2'] = 1\n",
    "        train_set.loc[(train_set['DateAnswered'] < '2019-09-01'), 'yr2'] = 0\n",
    "\n",
    "        # 'age',\n",
    "        train_set['age'] = train_set['DateAnswered'] - train_set['DateOfBirth'] \n",
    "\n",
    "        # 'term',\n",
    "        train_set['term'] = 6\n",
    "\n",
    "        train_set.loc[((train_set['DateAnswered'] >= '2018-09-04') & (train_set['DateAnswered'] < '2018-10-29')) |\n",
    "                      ((train_set['DateAnswered'] >= '2019-09-02') & (train_set['DateAnswered'] < '2019-10-28')),\n",
    "                      'term'] = 1\n",
    "\n",
    "        train_set.loc[((train_set['DateAnswered'] >= '2018-10-29') & (train_set['DateAnswered'] < '2019-01-03')) |\n",
    "                      ((train_set['DateAnswered'] >= '2019-10-28') & (train_set['DateAnswered'] < '2020-01-06')),\n",
    "                      'term'] = 2\n",
    "\n",
    "        train_set.loc[((train_set['DateAnswered'] >= '2019-01-03') & (train_set['DateAnswered'] < '2019-02-25')) |\n",
    "                      ((train_set['DateAnswered'] >= '2020-01-06') & (train_set['DateAnswered'] < '2020-02-24')),\n",
    "                      'term'] = 3\n",
    "\n",
    "        train_set.loc[((train_set['DateAnswered'] >= '2019-02-25') & (train_set['DateAnswered'] < '2019-04-23')) |\n",
    "                      ((train_set['DateAnswered'] >= '2020-02-24') & (train_set['DateAnswered'] < '2020-04-20')),\n",
    "                      'term'] = 4\n",
    "\n",
    "        train_set.loc[((train_set['DateAnswered'] >= '2019-04-23') & (train_set['DateAnswered'] < '2019-06-03')) |\n",
    "                      ((train_set['DateAnswered'] >= '2020-04-20') & (train_set['DateAnswered'] < '2020-06-01')),\n",
    "                      'term'] = 5\n",
    "\n",
    "        # 'time',\n",
    "        train_set['time'] = 4\n",
    "        train_set.loc[(train_set['DateAnswered'].dt.strftime(\"%H:%M:%S\") >= '08:00:00') &\n",
    "                      (train_set['DateAnswered'].dt.strftime(\"%H:%M:%S\") < '12:00:00')\n",
    "                       , 'time'] = 1\n",
    "\n",
    "        train_set.loc[(train_set['DateAnswered'].dt.strftime(\"%H:%M:%S\") >= '12:00:00') &\n",
    "                      (train_set['DateAnswered'].dt.strftime(\"%H:%M:%S\") < '16:00:00')\n",
    "                       , 'time'] = 2\n",
    "\n",
    "        train_set.loc[(train_set['DateAnswered'].dt.strftime(\"%H:%M:%S\") >= '16:00:00') &\n",
    "                      (train_set['DateAnswered'].dt.strftime(\"%H:%M:%S\") < '20:00:00')\n",
    "                       , 'time'] = 3\n",
    "\n",
    "        # 'is_weekend',\n",
    "        train_set['is_weekend'] = 0\n",
    "        train_set.loc[train_set['DateAnswered'].dt.dayofweek > 4, 'is_weekend'] = 1\n",
    "\n",
    "        # 'last_answered', adds repeat as well\n",
    "        train_set.sort_values(['UserId', 'DateAnswered'], inplace=True)\n",
    "        train_set['last_answered'] = train_set['DateAnswered'] - datetime.datetime.strptime('2018-09-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "        train_set['repeat'] = (train_set['UserId']==train_set['UserId'].shift(1))\n",
    "        train_set.loc[train_set['repeat'] == True, 'last_answered'] = train_set['DateAnswered'].diff()\n",
    "        \n",
    "        # get rid of values\n",
    "        train_set.drop('IsCorrect', axis=1, inplace=True)\n",
    "        train_set.drop('DateAnswered', axis=1, inplace=True) # added\n",
    "        train_set.drop('DateOfBirth', axis=1, inplace=True) # added\n",
    "        # think issue is here\n",
    "#         train_set['DateAnswered'] = train_set['DateAnswered'].values.astype('float')\n",
    "#         train_set['DateOfBirth'] = train_set['DateOfBirth'].values.astype('float')\n",
    "            \n",
    "        return train_set\n",
    "\n",
    "attr_adder = CombinedAttributesAdder()\n",
    "training_extra_attribs = attr_adder.transform(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99eb9dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data for ML algos\n",
    "# they use strat_train_set - think should do this based on confidence value\n",
    "# getting equal missing values\n",
    "IsCorrect = train_set.drop('IsCorrect', axis=1)\n",
    "IsCorrect_labels = train_set['IsCorrect'].copy()\n",
    "AnswerValue = train_set.drop('AnswerValue', axis=1)\n",
    "AnswerValue_labels = train_set['AnswerValue'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30271443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-13b299ff3824>:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['DateAnswered_float'] = train_set['DateAnswered'].values.astype('float')\n",
      "<ipython-input-15-13b299ff3824>:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['DateOfBirth_float'] = train_set['DateOfBirth'].values.astype('float')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>AnswerId</th>\n",
       "      <th>IsCorrect</th>\n",
       "      <th>CorrectAnswer</th>\n",
       "      <th>AnswerValue</th>\n",
       "      <th>DateAnswered</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Gender</th>\n",
       "      <th>DateOfBirth</th>\n",
       "      <th>...</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>3</th>\n",
       "      <th>DateAnswered_float</th>\n",
       "      <th>DateOfBirth_float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27185</td>\n",
       "      <td>40527</td>\n",
       "      <td>10797164</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-18 22:03:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.552947e+18</td>\n",
       "      <td>1.093997e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>27185</td>\n",
       "      <td>102085</td>\n",
       "      <td>11623933</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-21 20:08:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2005-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.574367e+18</td>\n",
       "      <td>1.125533e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>27185</td>\n",
       "      <td>86279</td>\n",
       "      <td>11606301</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-02-09 12:45:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2004-07-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.549716e+18</td>\n",
       "      <td>1.088640e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27185</td>\n",
       "      <td>55310</td>\n",
       "      <td>15582540</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-22 18:45:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2003-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.555959e+18</td>\n",
       "      <td>1.062374e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>27185</td>\n",
       "      <td>34815</td>\n",
       "      <td>7797864</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-20 18:28:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006-02-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.574274e+18</td>\n",
       "      <td>1.138752e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692074</th>\n",
       "      <td>3543</td>\n",
       "      <td>52636</td>\n",
       "      <td>8100523</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-04-22 12:57:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006-12-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.587560e+18</td>\n",
       "      <td>1.164931e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692077</th>\n",
       "      <td>3543</td>\n",
       "      <td>55302</td>\n",
       "      <td>12832011</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-04-21 11:13:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-03-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.587468e+18</td>\n",
       "      <td>1.172707e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692079</th>\n",
       "      <td>3543</td>\n",
       "      <td>4938</td>\n",
       "      <td>7281923</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-04-17 12:45:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-11-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.587128e+18</td>\n",
       "      <td>1.162339e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692080</th>\n",
       "      <td>3543</td>\n",
       "      <td>16245</td>\n",
       "      <td>18876238</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-04-20 07:18:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.587367e+18</td>\n",
       "      <td>1.167610e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692733</th>\n",
       "      <td>1384</td>\n",
       "      <td>51810</td>\n",
       "      <td>8704586</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-03-16 15:29:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.552750e+18</td>\n",
       "      <td>1.372637e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537824 rows × 319 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          QuestionId  UserId  AnswerId  IsCorrect  CorrectAnswer  AnswerValue  \\\n",
       "6              27185   40527  10797164          1              1            1   \n",
       "20             27185  102085  11623933          1              1            1   \n",
       "24             27185   86279  11606301          0              1            2   \n",
       "26             27185   55310  15582540          1              1            1   \n",
       "33             27185   34815   7797864          1              1            1   \n",
       "...              ...     ...       ...        ...            ...          ...   \n",
       "12692074        3543   52636   8100523          1              2            2   \n",
       "12692077        3543   55302  12832011          1              2            2   \n",
       "12692079        3543    4938   7281923          0              2            4   \n",
       "12692080        3543   16245  18876238          0              2            4   \n",
       "12692733        1384   51810   8704586          1              3            3   \n",
       "\n",
       "                DateAnswered  Confidence  Gender DateOfBirth  ...   93   94  \\\n",
       "6        2019-03-18 22:03:00       100.0       1  2004-09-01  ...    0    0   \n",
       "20       2019-11-21 20:08:00        50.0       1  2005-09-01  ...    0    0   \n",
       "24       2019-02-09 12:45:00        50.0       2  2004-07-01  ...    0    0   \n",
       "26       2019-04-22 18:45:00       100.0       2  2003-09-01  ...    0    0   \n",
       "33       2019-11-20 18:28:00       100.0       2  2006-02-01  ...    0    0   \n",
       "...                      ...         ...     ...         ...  ...  ...  ...   \n",
       "12692074 2020-04-22 12:57:00       100.0       2  2006-12-01  ...    0    0   \n",
       "12692077 2020-04-21 11:13:00       100.0       1  2007-03-01  ...    0    0   \n",
       "12692079 2020-04-17 12:45:00         0.0       1  2006-11-01  ...    0    0   \n",
       "12692080 2020-04-20 07:18:00        50.0       2  2007-01-01  ...    0    0   \n",
       "12692733 2019-03-16 15:29:00       100.0       2  2013-07-01  ...    0    0   \n",
       "\n",
       "           95   96   97   98   99  3  DateAnswered_float  DateOfBirth_float  \n",
       "6           0    0    0    0    0  1        1.552947e+18       1.093997e+18  \n",
       "20          0    0    0    0    0  1        1.574367e+18       1.125533e+18  \n",
       "24          0    0    0    0    0  1        1.549716e+18       1.088640e+18  \n",
       "26          0    0    0    0    0  1        1.555959e+18       1.062374e+18  \n",
       "33          0    0    0    0    0  1        1.574274e+18       1.138752e+18  \n",
       "...       ...  ...  ...  ...  ... ..                 ...                ...  \n",
       "12692074    0    0    0    0    0  1        1.587560e+18       1.164931e+18  \n",
       "12692077    0    0    0    0    0  1        1.587468e+18       1.172707e+18  \n",
       "12692079    0    0    0    0    0  1        1.587128e+18       1.162339e+18  \n",
       "12692080    0    0    0    0    0  1        1.587367e+18       1.167610e+18  \n",
       "12692733    0    0    0    0    0  1        1.552750e+18       1.372637e+18  \n",
       "\n",
       "[537824 rows x 319 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['DateAnswered_float'] = train_set['DateAnswered'].values.astype('float')\n",
    "train_set['DateOfBirth_float'] = train_set['DateOfBirth'].values.astype('float')\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3102d505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-d2c21bca1d9d>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['yr2'] = 1\n",
      "<ipython-input-25-d2c21bca1d9d>:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['age'] = train_set['DateAnswered'] - train_set['DateOfBirth']\n",
      "<ipython-input-25-d2c21bca1d9d>:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['term'] = 6\n",
      "<ipython-input-25-d2c21bca1d9d>:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['time'] = 4\n",
      "<ipython-input-25-d2c21bca1d9d>:111: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['is_weekend'] = 0\n",
      "<ipython-input-25-d2c21bca1d9d>:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['last_answered'] = train_set['DateAnswered'] - datetime.datetime.strptime('2018-09-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
      "<ipython-input-25-d2c21bca1d9d>:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_set['repeat'] = (train_set['UserId']==train_set['UserId'].shift(1))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:572: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'Timedelta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-ab9490f1921d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;31m# IsCorrect_prepared = full_pipeline.fit_transform(train_set)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[0mIsCorrect_prepared\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;31m# IsCorrect_prepared = num_pipeline.fit_transform()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_hstack\u001b[1;34m(self, Xs)\u001b[0m\n\u001b[0;32m    586\u001b[0m                 \u001b[1;31m# in a sparse matrix, `check_array` is used for the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m                 \u001b[1;31m# dtype conversion if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m                 converted_Xs = [check_array(X,\n\u001b[0m\u001b[0;32m    589\u001b[0m                                             \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m                                             force_all_finite=False)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    586\u001b[0m                 \u001b[1;31m# in a sparse matrix, `check_array` is used for the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m                 \u001b[1;31m# dtype conversion if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m                 converted_Xs = [check_array(X,\n\u001b[0m\u001b[0;32m    589\u001b[0m                                             \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m                                             force_all_finite=False)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m                 raise ValueError(\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'Timedelta'"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "cat_attribs = ['QuestionId',\n",
    " 'UserId',\n",
    " 'AnswerId',\n",
    " 'CorrectAnswer',\n",
    " 'AnswerValue',\n",
    " 'Confidence',\n",
    " 'Gender',\n",
    " 'PremiumPupil']\n",
    "\n",
    "num_attribs = list(IsCorrect.drop(cat_attribs, axis=1))\n",
    "num_attribs.remove('DateAnswered')\n",
    "num_attribs.remove('DateOfBirth')\n",
    "\n",
    "# all_attribs = cat_attribs + num_attribs\n",
    "# all_attribs.append('IsCorrect')\n",
    "\n",
    "all_attribs = list(train_set.drop(['DateAnswered_float', 'DateOfBirth_float'], axis=1))\n",
    "\n",
    "# cat_attribs = ['QuestionId', 'UserId', 'AnswerId','CorrectAnswer', 'AnswerValue', 'Confidence', 'Gender', 'PremiumPupil', 'time', 'term']\n",
    "# training_num = training_extra_attribs.drop(cat_attribs, axis=1)\n",
    "# training_num['unique_day'] = 0\n",
    "# num_attribs = list(training_num)\n",
    "\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "#         ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "#         ('attribs_adder', CombinedAttributesAdder()),\n",
    "        ('std_scaler', StandardScaler(with_mean=False)),\n",
    "    ])\n",
    "\n",
    "# all_pipeline = Pipeline([\n",
    "#         ('attribs_adder', CombinedAttributesAdder()),\n",
    "#         ('scale values', StandardScaler(with_mean=False)),\n",
    "#     ])\n",
    "\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        ('all', CombinedAttributesAdder(), all_attribs),\n",
    "        ('num', num_pipeline, num_attribs),\n",
    "        ('cat', OneHotEncoder(), cat_attribs), # trying this as an extra but this should now work\n",
    "    ])\n",
    "\n",
    "# IsCorrect_prepared = full_pipeline.fit_transform(train_set)\n",
    "\n",
    "IsCorrect_prepared = full_pipeline.fit_transform(train_set)\n",
    "# IsCorrect_prepared = num_pipeline.fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08504cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# still got error TypeError: float() argument must be a string or a number, not 'Timedelta'\n",
    "\n",
    "IsCorrect_prepared\n",
    "# this should now work - stay until finished running just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c6b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note this actually has run successfully thank god\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(C=1.0, penalty='l1', solver='liblinear')\n",
    "log_reg.fit(IsCorrect_prepared, IsCorrect_labels)\n",
    "log_reg_predictions = log_reg.predict(IsCorrect_prepared) # will give you 0 or 1 as the class\n",
    "log_reg_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaeb78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "log_reg_mse = mean_squared_error(IsCorrect_labels, log_reg_predictions)\n",
    "log_reg_rmse = np.sqrt(log_reg_mse)\n",
    "log_reg_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82beb130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff7aab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dd0678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "\n",
    "# from https://colab.research.google.com/github/ageron/handson-ml2/blob/master/03_classification.ipynb#scrollTo=oWMedzLJ47vb \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "#y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(IsCorrect_labels, log_reg_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbe8097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(IsCorrect_labels, log_reg_predictions, normalize=False)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d857e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check this with sensitivity & specicivity\n",
    "# F1-score\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(IsCorrect_labels, log_reg_predictions)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa061766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0e5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specificity - should work may need to just get values from corr - matrix\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = [0, 1]\n",
    "print(classification_report(IsCorrect_labels, log_reg_predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db0e8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f747ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridcv search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c34ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfd9b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split columns into numerical and categorical\n",
    "cat_attribs = ['QuestionId', 'UserId', 'AnswerId','CorrectAnswer', 'AnswerValue', 'Confidence', 'Gender', 'PremiumPupil', 'time', 'term']\n",
    "training_num = training_extra_attribs.drop(cat_attribs, axis=1)\n",
    "training_num['unique_day'] = 0\n",
    "num_attribs = list(training_num)\n",
    "# all_attribs = list(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcac974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c735b9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458b7abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8be8f1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "unique_student_train = pd.DataFrame(data=train_set['UserId'].unique(), columns=['UserId'])\n",
    "print('2')\n",
    "unique_student_train['unique_day'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0143a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['QuestionId',\n",
       " 'UserId',\n",
       " 'AnswerId',\n",
       " 'CorrectAnswer',\n",
       " 'AnswerValue',\n",
       " 'DateAnswered',\n",
       " 'Confidence',\n",
       " 'Gender',\n",
       " 'DateOfBirth',\n",
       " 'PremiumPupil',\n",
       " ' 100',\n",
       " ' 101',\n",
       " ' 102',\n",
       " ' 103',\n",
       " ' 104',\n",
       " ' 105',\n",
       " ' 1059',\n",
       " ' 106',\n",
       " ' 107',\n",
       " ' 1077',\n",
       " ' 1078',\n",
       " ' 1079',\n",
       " ' 108',\n",
       " ' 1080',\n",
       " ' 1081',\n",
       " ' 1082',\n",
       " ' 109',\n",
       " ' 110',\n",
       " ' 111',\n",
       " ' 112',\n",
       " ' 113',\n",
       " ' 114',\n",
       " ' 115',\n",
       " ' 1156',\n",
       " ' 1157',\n",
       " ' 1158',\n",
       " ' 1159',\n",
       " ' 116',\n",
       " ' 1160',\n",
       " ' 1161',\n",
       " ' 1162',\n",
       " ' 1163',\n",
       " ' 1164',\n",
       " ' 1165',\n",
       " ' 1167',\n",
       " ' 1169',\n",
       " ' 117',\n",
       " ' 1171',\n",
       " ' 1174',\n",
       " ' 1175',\n",
       " ' 1176',\n",
       " ' 1179',\n",
       " ' 118',\n",
       " ' 1180',\n",
       " ' 1181',\n",
       " ' 1182',\n",
       " ' 1184',\n",
       " ' 1185',\n",
       " ' 1186',\n",
       " ' 1187',\n",
       " ' 1188',\n",
       " ' 119',\n",
       " ' 1203',\n",
       " ' 1208',\n",
       " ' 1209',\n",
       " ' 1210',\n",
       " ' 1212',\n",
       " ' 1213',\n",
       " ' 1214',\n",
       " ' 1215',\n",
       " ' 1218',\n",
       " ' 1263',\n",
       " ' 1265',\n",
       " ' 1266',\n",
       " ' 141',\n",
       " ' 144',\n",
       " ' 146',\n",
       " ' 149',\n",
       " ' 152',\n",
       " ' 153',\n",
       " ' 154',\n",
       " ' 156',\n",
       " ' 157',\n",
       " ' 158',\n",
       " ' 159',\n",
       " ' 160',\n",
       " ' 163',\n",
       " ' 1636',\n",
       " ' 164',\n",
       " ' 1642',\n",
       " ' 1647',\n",
       " ' 1648',\n",
       " ' 1649',\n",
       " ' 165',\n",
       " ' 1650',\n",
       " ' 1651',\n",
       " ' 166',\n",
       " ' 167',\n",
       " ' 1676',\n",
       " ' 168',\n",
       " ' 171',\n",
       " ' 172',\n",
       " ' 173',\n",
       " ' 174',\n",
       " ' 175',\n",
       " ' 1750',\n",
       " ' 176',\n",
       " ' 177',\n",
       " ' 178',\n",
       " ' 179',\n",
       " ' 180',\n",
       " ' 181',\n",
       " ' 182',\n",
       " ' 183',\n",
       " ' 184',\n",
       " ' 185',\n",
       " ' 186',\n",
       " ' 187',\n",
       " ' 188',\n",
       " ' 189',\n",
       " ' 190',\n",
       " ' 191',\n",
       " ' 192',\n",
       " ' 193',\n",
       " ' 195',\n",
       " ' 196',\n",
       " ' 197',\n",
       " ' 1975',\n",
       " ' 198',\n",
       " ' 1982',\n",
       " ' 199',\n",
       " ' 200',\n",
       " ' 202',\n",
       " ' 203',\n",
       " ' 204',\n",
       " ' 205',\n",
       " ' 206',\n",
       " ' 207',\n",
       " ' 208',\n",
       " ' 209',\n",
       " ' 210',\n",
       " ' 211',\n",
       " ' 212',\n",
       " ' 213',\n",
       " ' 214',\n",
       " ' 215',\n",
       " ' 216',\n",
       " ' 217',\n",
       " ' 218',\n",
       " ' 219',\n",
       " ' 220',\n",
       " ' 221',\n",
       " ' 222',\n",
       " ' 223',\n",
       " ' 224',\n",
       " ' 225',\n",
       " ' 226',\n",
       " ' 227',\n",
       " ' 228',\n",
       " ' 229',\n",
       " ' 230',\n",
       " ' 231',\n",
       " ' 232',\n",
       " ' 233',\n",
       " ' 234',\n",
       " ' 235',\n",
       " ' 236',\n",
       " ' 237',\n",
       " ' 238',\n",
       " ' 239',\n",
       " ' 240',\n",
       " ' 241',\n",
       " ' 242',\n",
       " ' 243',\n",
       " ' 244',\n",
       " ' 245',\n",
       " ' 246',\n",
       " ' 247',\n",
       " ' 248',\n",
       " ' 249',\n",
       " ' 250',\n",
       " ' 251',\n",
       " ' 252',\n",
       " ' 253',\n",
       " ' 254',\n",
       " ' 255',\n",
       " ' 256',\n",
       " ' 257',\n",
       " ' 258',\n",
       " ' 259',\n",
       " ' 260',\n",
       " ' 261',\n",
       " ' 262',\n",
       " ' 263',\n",
       " ' 264',\n",
       " ' 265',\n",
       " ' 266',\n",
       " ' 267',\n",
       " ' 268',\n",
       " ' 269',\n",
       " ' 270',\n",
       " ' 271',\n",
       " ' 272',\n",
       " ' 273',\n",
       " ' 274',\n",
       " ' 275',\n",
       " ' 276',\n",
       " ' 277',\n",
       " ' 278',\n",
       " ' 279',\n",
       " ' 280',\n",
       " ' 281',\n",
       " ' 282',\n",
       " ' 283',\n",
       " ' 284',\n",
       " ' 298',\n",
       " ' 32',\n",
       " ' 33',\n",
       " ' 331',\n",
       " ' 332',\n",
       " ' 334',\n",
       " ' 335',\n",
       " ' 336',\n",
       " ' 337',\n",
       " ' 338',\n",
       " ' 339',\n",
       " ' 34',\n",
       " ' 340',\n",
       " ' 341',\n",
       " ' 342',\n",
       " ' 343',\n",
       " ' 344',\n",
       " ' 348',\n",
       " ' 349',\n",
       " ' 35',\n",
       " ' 350',\n",
       " ' 353',\n",
       " ' 36',\n",
       " ' 37',\n",
       " ' 38',\n",
       " ' 39',\n",
       " ' 40',\n",
       " ' 406',\n",
       " ' 408',\n",
       " ' 409',\n",
       " ' 41',\n",
       " ' 410',\n",
       " ' 42',\n",
       " ' 434',\n",
       " ' 436',\n",
       " ' 437',\n",
       " ' 439',\n",
       " ' 44',\n",
       " ' 45',\n",
       " ' 46',\n",
       " ' 47',\n",
       " ' 48',\n",
       " ' 49',\n",
       " ' 50',\n",
       " ' 51',\n",
       " ' 52',\n",
       " ' 53',\n",
       " ' 54',\n",
       " ' 540',\n",
       " ' 55',\n",
       " ' 56',\n",
       " ' 57',\n",
       " ' 58',\n",
       " ' 59',\n",
       " ' 60',\n",
       " ' 61',\n",
       " ' 62',\n",
       " ' 63',\n",
       " ' 64',\n",
       " ' 649',\n",
       " ' 65',\n",
       " ' 655',\n",
       " ' 656',\n",
       " ' 657',\n",
       " ' 66',\n",
       " ' 67',\n",
       " ' 68',\n",
       " ' 69',\n",
       " ' 692',\n",
       " ' 698',\n",
       " ' 70',\n",
       " ' 700',\n",
       " ' 71',\n",
       " ' 72',\n",
       " ' 73',\n",
       " ' 74',\n",
       " ' 75',\n",
       " ' 76',\n",
       " ' 77',\n",
       " ' 78',\n",
       " ' 79',\n",
       " ' 80',\n",
       " ' 81',\n",
       " ' 83',\n",
       " ' 84',\n",
       " ' 85',\n",
       " ' 86',\n",
       " ' 87',\n",
       " ' 88',\n",
       " ' 89',\n",
       " ' 90',\n",
       " ' 91',\n",
       " ' 92',\n",
       " ' 93',\n",
       " ' 94',\n",
       " ' 95',\n",
       " ' 96',\n",
       " ' 97',\n",
       " ' 98',\n",
       " ' 99',\n",
       " '3']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['QuestionId',\n",
    " 'UserId',\n",
    " 'AnswerId',\n",
    " 'CorrectAnswer',\n",
    " 'AnswerValue',\n",
    " 'Confidence',\n",
    " 'Gender',\n",
    " 'PremiumPupil']\n",
    "\n",
    "\n",
    "train_set['DateAnswered'] = train_set['DateAnswered'].values.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09146639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>AnswerId</th>\n",
       "      <th>CorrectAnswer</th>\n",
       "      <th>AnswerValue</th>\n",
       "      <th>DateAnswered</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Gender</th>\n",
       "      <th>DateOfBirth</th>\n",
       "      <th>PremiumPupil</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27185</td>\n",
       "      <td>40527</td>\n",
       "      <td>10797164</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-18 22:03:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-09-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>27185</td>\n",
       "      <td>102085</td>\n",
       "      <td>11623933</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-21 20:08:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2005-09-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>27185</td>\n",
       "      <td>86279</td>\n",
       "      <td>11606301</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-02-09 12:45:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2004-07-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27185</td>\n",
       "      <td>55310</td>\n",
       "      <td>15582540</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-22 18:45:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2003-09-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>27185</td>\n",
       "      <td>34815</td>\n",
       "      <td>7797864</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-20 18:28:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 316 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    QuestionId  UserId  AnswerId  CorrectAnswer  AnswerValue  \\\n",
       "6        27185   40527  10797164              1            1   \n",
       "20       27185  102085  11623933              1            1   \n",
       "24       27185   86279  11606301              1            2   \n",
       "26       27185   55310  15582540              1            1   \n",
       "33       27185   34815   7797864              1            1   \n",
       "\n",
       "          DateAnswered  Confidence  Gender DateOfBirth  PremiumPupil  ...  \\\n",
       "6  2019-03-18 22:03:00       100.0       1  2004-09-01           0.0  ...   \n",
       "20 2019-11-21 20:08:00        50.0       1  2005-09-01           0.0  ...   \n",
       "24 2019-02-09 12:45:00        50.0       2  2004-07-01           1.0  ...   \n",
       "26 2019-04-22 18:45:00       100.0       2  2003-09-01           0.0  ...   \n",
       "33 2019-11-20 18:28:00       100.0       2  2006-02-01           0.0  ...   \n",
       "\n",
       "     91   92   93   94   95   96   97   98   99  3  \n",
       "6     0    0    0    0    0    0    0    0    0  1  \n",
       "20    0    0    0    0    0    0    0    0    0  1  \n",
       "24    0    0    0    0    0    0    0    0    0  1  \n",
       "26    0    0    0    0    0    0    0    0    0  1  \n",
       "33    0    0    0    0    0    0    0    0    0  1  \n",
       "\n",
       "[5 rows x 316 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IsCorrect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8d99811a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>AnswerId</th>\n",
       "      <th>IsCorrect</th>\n",
       "      <th>CorrectAnswer</th>\n",
       "      <th>AnswerValue</th>\n",
       "      <th>DateAnswered</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Gender</th>\n",
       "      <th>DateOfBirth</th>\n",
       "      <th>...</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>3</th>\n",
       "      <th>DateAnswered_float</th>\n",
       "      <th>DateOfBirth_float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27185</td>\n",
       "      <td>40527</td>\n",
       "      <td>10797164</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-18 22:03:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.552947e+18</td>\n",
       "      <td>1.093997e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>27185</td>\n",
       "      <td>102085</td>\n",
       "      <td>11623933</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-21 20:08:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2005-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.574367e+18</td>\n",
       "      <td>1.125533e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>27185</td>\n",
       "      <td>86279</td>\n",
       "      <td>11606301</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-02-09 12:45:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2004-07-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.549716e+18</td>\n",
       "      <td>1.088640e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27185</td>\n",
       "      <td>55310</td>\n",
       "      <td>15582540</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-22 18:45:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2003-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.555959e+18</td>\n",
       "      <td>1.062374e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>27185</td>\n",
       "      <td>34815</td>\n",
       "      <td>7797864</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-20 18:28:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006-02-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.574274e+18</td>\n",
       "      <td>1.138752e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692074</th>\n",
       "      <td>3543</td>\n",
       "      <td>52636</td>\n",
       "      <td>8100523</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-04-22 12:57:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006-12-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.587560e+18</td>\n",
       "      <td>1.164931e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692077</th>\n",
       "      <td>3543</td>\n",
       "      <td>55302</td>\n",
       "      <td>12832011</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-04-21 11:13:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-03-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.587468e+18</td>\n",
       "      <td>1.172707e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692079</th>\n",
       "      <td>3543</td>\n",
       "      <td>4938</td>\n",
       "      <td>7281923</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-04-17 12:45:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-11-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.587128e+18</td>\n",
       "      <td>1.162339e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692080</th>\n",
       "      <td>3543</td>\n",
       "      <td>16245</td>\n",
       "      <td>18876238</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-04-20 07:18:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.587367e+18</td>\n",
       "      <td>1.167610e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692733</th>\n",
       "      <td>1384</td>\n",
       "      <td>51810</td>\n",
       "      <td>8704586</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-03-16 15:29:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.552750e+18</td>\n",
       "      <td>1.372637e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537824 rows × 319 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          QuestionId  UserId  AnswerId  IsCorrect  CorrectAnswer  AnswerValue  \\\n",
       "6              27185   40527  10797164          1              1            1   \n",
       "20             27185  102085  11623933          1              1            1   \n",
       "24             27185   86279  11606301          0              1            2   \n",
       "26             27185   55310  15582540          1              1            1   \n",
       "33             27185   34815   7797864          1              1            1   \n",
       "...              ...     ...       ...        ...            ...          ...   \n",
       "12692074        3543   52636   8100523          1              2            2   \n",
       "12692077        3543   55302  12832011          1              2            2   \n",
       "12692079        3543    4938   7281923          0              2            4   \n",
       "12692080        3543   16245  18876238          0              2            4   \n",
       "12692733        1384   51810   8704586          1              3            3   \n",
       "\n",
       "                DateAnswered  Confidence  Gender DateOfBirth  ...   93   94  \\\n",
       "6        2019-03-18 22:03:00       100.0       1  2004-09-01  ...    0    0   \n",
       "20       2019-11-21 20:08:00        50.0       1  2005-09-01  ...    0    0   \n",
       "24       2019-02-09 12:45:00        50.0       2  2004-07-01  ...    0    0   \n",
       "26       2019-04-22 18:45:00       100.0       2  2003-09-01  ...    0    0   \n",
       "33       2019-11-20 18:28:00       100.0       2  2006-02-01  ...    0    0   \n",
       "...                      ...         ...     ...         ...  ...  ...  ...   \n",
       "12692074 2020-04-22 12:57:00       100.0       2  2006-12-01  ...    0    0   \n",
       "12692077 2020-04-21 11:13:00       100.0       1  2007-03-01  ...    0    0   \n",
       "12692079 2020-04-17 12:45:00         0.0       1  2006-11-01  ...    0    0   \n",
       "12692080 2020-04-20 07:18:00        50.0       2  2007-01-01  ...    0    0   \n",
       "12692733 2019-03-16 15:29:00       100.0       2  2013-07-01  ...    0    0   \n",
       "\n",
       "           95   96   97   98   99  3  DateAnswered_float  DateOfBirth_float  \n",
       "6           0    0    0    0    0  1        1.552947e+18       1.093997e+18  \n",
       "20          0    0    0    0    0  1        1.574367e+18       1.125533e+18  \n",
       "24          0    0    0    0    0  1        1.549716e+18       1.088640e+18  \n",
       "26          0    0    0    0    0  1        1.555959e+18       1.062374e+18  \n",
       "33          0    0    0    0    0  1        1.574274e+18       1.138752e+18  \n",
       "...       ...  ...  ...  ...  ... ..                 ...                ...  \n",
       "12692074    0    0    0    0    0  1        1.587560e+18       1.164931e+18  \n",
       "12692077    0    0    0    0    0  1        1.587468e+18       1.172707e+18  \n",
       "12692079    0    0    0    0    0  1        1.587128e+18       1.162339e+18  \n",
       "12692080    0    0    0    0    0  1        1.587367e+18       1.167610e+18  \n",
       "12692733    0    0    0    0    0  1        1.552750e+18       1.372637e+18  \n",
       "\n",
       "[537824 rows x 319 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['DateAnswered_float'] = train_set['DateAnswered'].values.astype('float')\n",
    "train_set['DateOfBirth_float'] = train_set['DateOfBirth'].values.astype('float')\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ddc17a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>AnswerId</th>\n",
       "      <th>IsCorrect</th>\n",
       "      <th>CorrectAnswer</th>\n",
       "      <th>AnswerValue</th>\n",
       "      <th>DateAnswered</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Gender</th>\n",
       "      <th>DateOfBirth</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27185</td>\n",
       "      <td>40527</td>\n",
       "      <td>10797164</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-18 22:03:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>27185</td>\n",
       "      <td>102085</td>\n",
       "      <td>11623933</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-21 20:08:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2005-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>27185</td>\n",
       "      <td>86279</td>\n",
       "      <td>11606301</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-02-09 12:45:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2004-07-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27185</td>\n",
       "      <td>55310</td>\n",
       "      <td>15582540</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-22 18:45:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2003-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>27185</td>\n",
       "      <td>34815</td>\n",
       "      <td>7797864</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-20 18:28:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006-02-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692074</th>\n",
       "      <td>3543</td>\n",
       "      <td>52636</td>\n",
       "      <td>8100523</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-04-22 12:57:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006-12-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692077</th>\n",
       "      <td>3543</td>\n",
       "      <td>55302</td>\n",
       "      <td>12832011</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-04-21 11:13:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-03-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692079</th>\n",
       "      <td>3543</td>\n",
       "      <td>4938</td>\n",
       "      <td>7281923</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-04-17 12:45:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-11-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692080</th>\n",
       "      <td>3543</td>\n",
       "      <td>16245</td>\n",
       "      <td>18876238</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-04-20 07:18:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692733</th>\n",
       "      <td>1384</td>\n",
       "      <td>51810</td>\n",
       "      <td>8704586</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-03-16 15:29:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537824 rows × 317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          QuestionId  UserId  AnswerId  IsCorrect  CorrectAnswer  AnswerValue  \\\n",
       "6              27185   40527  10797164          1              1            1   \n",
       "20             27185  102085  11623933          1              1            1   \n",
       "24             27185   86279  11606301          0              1            2   \n",
       "26             27185   55310  15582540          1              1            1   \n",
       "33             27185   34815   7797864          1              1            1   \n",
       "...              ...     ...       ...        ...            ...          ...   \n",
       "12692074        3543   52636   8100523          1              2            2   \n",
       "12692077        3543   55302  12832011          1              2            2   \n",
       "12692079        3543    4938   7281923          0              2            4   \n",
       "12692080        3543   16245  18876238          0              2            4   \n",
       "12692733        1384   51810   8704586          1              3            3   \n",
       "\n",
       "                DateAnswered  Confidence  Gender DateOfBirth  ...   91   92  \\\n",
       "6        2019-03-18 22:03:00       100.0       1  2004-09-01  ...    0    0   \n",
       "20       2019-11-21 20:08:00        50.0       1  2005-09-01  ...    0    0   \n",
       "24       2019-02-09 12:45:00        50.0       2  2004-07-01  ...    0    0   \n",
       "26       2019-04-22 18:45:00       100.0       2  2003-09-01  ...    0    0   \n",
       "33       2019-11-20 18:28:00       100.0       2  2006-02-01  ...    0    0   \n",
       "...                      ...         ...     ...         ...  ...  ...  ...   \n",
       "12692074 2020-04-22 12:57:00       100.0       2  2006-12-01  ...    0    0   \n",
       "12692077 2020-04-21 11:13:00       100.0       1  2007-03-01  ...    0    0   \n",
       "12692079 2020-04-17 12:45:00         0.0       1  2006-11-01  ...    0    0   \n",
       "12692080 2020-04-20 07:18:00        50.0       2  2007-01-01  ...    0    0   \n",
       "12692733 2019-03-16 15:29:00       100.0       2  2013-07-01  ...    0    0   \n",
       "\n",
       "           93   94   95   96   97   98   99  3  \n",
       "6           0    0    0    0    0    0    0  1  \n",
       "20          0    0    0    0    0    0    0  1  \n",
       "24          0    0    0    0    0    0    0  1  \n",
       "26          0    0    0    0    0    0    0  1  \n",
       "33          0    0    0    0    0    0    0  1  \n",
       "...       ...  ...  ...  ...  ...  ...  ... ..  \n",
       "12692074    0    0    0    0    0    0    0  1  \n",
       "12692077    0    0    0    0    0    0    0  1  \n",
       "12692079    0    0    0    0    0    0    0  1  \n",
       "12692080    0    0    0    0    0    0    0  1  \n",
       "12692733    0    0    0    0    0    0    0  1  \n",
       "\n",
       "[537824 rows x 317 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452861a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs\n",
    "\n",
    "TypeError: float() argument must be a string or a number, not 'Timedelta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1fdf3027",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attribs = ['QuestionId',\n",
    " 'UserId',\n",
    " 'AnswerId',\n",
    " 'CorrectAnswer',\n",
    " 'AnswerValue',\n",
    " 'Confidence',\n",
    " 'Gender',\n",
    " 'PremiumPupil']\n",
    "\n",
    "num_attribs = list(IsCorrect.drop(cat_attribs, axis=1))\n",
    "\n",
    "# all_attribs = cat_attribs + num_attribs\n",
    "# all_attribs.append('IsCorrect')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "350bf9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['QuestionId',\n",
       " 'UserId',\n",
       " 'AnswerId',\n",
       " 'CorrectAnswer',\n",
       " 'AnswerValue',\n",
       " 'Confidence',\n",
       " 'Gender',\n",
       " 'PremiumPupil',\n",
       " 'DateAnswered',\n",
       " 'DateOfBirth',\n",
       " ' 100',\n",
       " ' 101',\n",
       " ' 102',\n",
       " ' 103',\n",
       " ' 104',\n",
       " ' 105',\n",
       " ' 1059',\n",
       " ' 106',\n",
       " ' 107',\n",
       " ' 1077',\n",
       " ' 1078',\n",
       " ' 1079',\n",
       " ' 108',\n",
       " ' 1080',\n",
       " ' 1081',\n",
       " ' 1082',\n",
       " ' 109',\n",
       " ' 110',\n",
       " ' 111',\n",
       " ' 112',\n",
       " ' 113',\n",
       " ' 114',\n",
       " ' 115',\n",
       " ' 1156',\n",
       " ' 1157',\n",
       " ' 1158',\n",
       " ' 1159',\n",
       " ' 116',\n",
       " ' 1160',\n",
       " ' 1161',\n",
       " ' 1162',\n",
       " ' 1163',\n",
       " ' 1164',\n",
       " ' 1165',\n",
       " ' 1167',\n",
       " ' 1169',\n",
       " ' 117',\n",
       " ' 1171',\n",
       " ' 1174',\n",
       " ' 1175',\n",
       " ' 1176',\n",
       " ' 1179',\n",
       " ' 118',\n",
       " ' 1180',\n",
       " ' 1181',\n",
       " ' 1182',\n",
       " ' 1184',\n",
       " ' 1185',\n",
       " ' 1186',\n",
       " ' 1187',\n",
       " ' 1188',\n",
       " ' 119',\n",
       " ' 1203',\n",
       " ' 1208',\n",
       " ' 1209',\n",
       " ' 1210',\n",
       " ' 1212',\n",
       " ' 1213',\n",
       " ' 1214',\n",
       " ' 1215',\n",
       " ' 1218',\n",
       " ' 1263',\n",
       " ' 1265',\n",
       " ' 1266',\n",
       " ' 141',\n",
       " ' 144',\n",
       " ' 146',\n",
       " ' 149',\n",
       " ' 152',\n",
       " ' 153',\n",
       " ' 154',\n",
       " ' 156',\n",
       " ' 157',\n",
       " ' 158',\n",
       " ' 159',\n",
       " ' 160',\n",
       " ' 163',\n",
       " ' 1636',\n",
       " ' 164',\n",
       " ' 1642',\n",
       " ' 1647',\n",
       " ' 1648',\n",
       " ' 1649',\n",
       " ' 165',\n",
       " ' 1650',\n",
       " ' 1651',\n",
       " ' 166',\n",
       " ' 167',\n",
       " ' 1676',\n",
       " ' 168',\n",
       " ' 171',\n",
       " ' 172',\n",
       " ' 173',\n",
       " ' 174',\n",
       " ' 175',\n",
       " ' 1750',\n",
       " ' 176',\n",
       " ' 177',\n",
       " ' 178',\n",
       " ' 179',\n",
       " ' 180',\n",
       " ' 181',\n",
       " ' 182',\n",
       " ' 183',\n",
       " ' 184',\n",
       " ' 185',\n",
       " ' 186',\n",
       " ' 187',\n",
       " ' 188',\n",
       " ' 189',\n",
       " ' 190',\n",
       " ' 191',\n",
       " ' 192',\n",
       " ' 193',\n",
       " ' 195',\n",
       " ' 196',\n",
       " ' 197',\n",
       " ' 1975',\n",
       " ' 198',\n",
       " ' 1982',\n",
       " ' 199',\n",
       " ' 200',\n",
       " ' 202',\n",
       " ' 203',\n",
       " ' 204',\n",
       " ' 205',\n",
       " ' 206',\n",
       " ' 207',\n",
       " ' 208',\n",
       " ' 209',\n",
       " ' 210',\n",
       " ' 211',\n",
       " ' 212',\n",
       " ' 213',\n",
       " ' 214',\n",
       " ' 215',\n",
       " ' 216',\n",
       " ' 217',\n",
       " ' 218',\n",
       " ' 219',\n",
       " ' 220',\n",
       " ' 221',\n",
       " ' 222',\n",
       " ' 223',\n",
       " ' 224',\n",
       " ' 225',\n",
       " ' 226',\n",
       " ' 227',\n",
       " ' 228',\n",
       " ' 229',\n",
       " ' 230',\n",
       " ' 231',\n",
       " ' 232',\n",
       " ' 233',\n",
       " ' 234',\n",
       " ' 235',\n",
       " ' 236',\n",
       " ' 237',\n",
       " ' 238',\n",
       " ' 239',\n",
       " ' 240',\n",
       " ' 241',\n",
       " ' 242',\n",
       " ' 243',\n",
       " ' 244',\n",
       " ' 245',\n",
       " ' 246',\n",
       " ' 247',\n",
       " ' 248',\n",
       " ' 249',\n",
       " ' 250',\n",
       " ' 251',\n",
       " ' 252',\n",
       " ' 253',\n",
       " ' 254',\n",
       " ' 255',\n",
       " ' 256',\n",
       " ' 257',\n",
       " ' 258',\n",
       " ' 259',\n",
       " ' 260',\n",
       " ' 261',\n",
       " ' 262',\n",
       " ' 263',\n",
       " ' 264',\n",
       " ' 265',\n",
       " ' 266',\n",
       " ' 267',\n",
       " ' 268',\n",
       " ' 269',\n",
       " ' 270',\n",
       " ' 271',\n",
       " ' 272',\n",
       " ' 273',\n",
       " ' 274',\n",
       " ' 275',\n",
       " ' 276',\n",
       " ' 277',\n",
       " ' 278',\n",
       " ' 279',\n",
       " ' 280',\n",
       " ' 281',\n",
       " ' 282',\n",
       " ' 283',\n",
       " ' 284',\n",
       " ' 298',\n",
       " ' 32',\n",
       " ' 33',\n",
       " ' 331',\n",
       " ' 332',\n",
       " ' 334',\n",
       " ' 335',\n",
       " ' 336',\n",
       " ' 337',\n",
       " ' 338',\n",
       " ' 339',\n",
       " ' 34',\n",
       " ' 340',\n",
       " ' 341',\n",
       " ' 342',\n",
       " ' 343',\n",
       " ' 344',\n",
       " ' 348',\n",
       " ' 349',\n",
       " ' 35',\n",
       " ' 350',\n",
       " ' 353',\n",
       " ' 36',\n",
       " ' 37',\n",
       " ' 38',\n",
       " ' 39',\n",
       " ' 40',\n",
       " ' 406',\n",
       " ' 408',\n",
       " ' 409',\n",
       " ' 41',\n",
       " ' 410',\n",
       " ' 42',\n",
       " ' 434',\n",
       " ' 436',\n",
       " ' 437',\n",
       " ' 439',\n",
       " ' 44',\n",
       " ' 45',\n",
       " ' 46',\n",
       " ' 47',\n",
       " ' 48',\n",
       " ' 49',\n",
       " ' 50',\n",
       " ' 51',\n",
       " ' 52',\n",
       " ' 53',\n",
       " ' 54',\n",
       " ' 540',\n",
       " ' 55',\n",
       " ' 56',\n",
       " ' 57',\n",
       " ' 58',\n",
       " ' 59',\n",
       " ' 60',\n",
       " ' 61',\n",
       " ' 62',\n",
       " ' 63',\n",
       " ' 64',\n",
       " ' 649',\n",
       " ' 65',\n",
       " ' 655',\n",
       " ' 656',\n",
       " ' 657',\n",
       " ' 66',\n",
       " ' 67',\n",
       " ' 68',\n",
       " ' 69',\n",
       " ' 692',\n",
       " ' 698',\n",
       " ' 70',\n",
       " ' 700',\n",
       " ' 71',\n",
       " ' 72',\n",
       " ' 73',\n",
       " ' 74',\n",
       " ' 75',\n",
       " ' 76',\n",
       " ' 77',\n",
       " ' 78',\n",
       " ' 79',\n",
       " ' 80',\n",
       " ' 81',\n",
       " ' 83',\n",
       " ' 84',\n",
       " ' 85',\n",
       " ' 86',\n",
       " ' 87',\n",
       " ' 88',\n",
       " ' 89',\n",
       " ' 90',\n",
       " ' 91',\n",
       " ' 92',\n",
       " ' 93',\n",
       " ' 94',\n",
       " ' 95',\n",
       " ' 96',\n",
       " ' 97',\n",
       " ' 98',\n",
       " ' 99',\n",
       " '3',\n",
       " 'IsCorrect']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2387dd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<537824x572746 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 169414560 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IsCorrect_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11566b4b",
   "metadata": {},
   "source": [
    "# 20.01 Lucy\n",
    "start again above\n",
    "unsure what is happeneing with the key error\n",
    "try to run book code https://github.com/ageron/handson-ml2/blob/master/02_end_to_end_machine_learning_project.ipynb\n",
    "see if that helps\n",
    "once pipeline works then we're looking a lot better\n",
    "\n",
    "think we're gonna use random forest but maybe do some more research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ede41d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19c3704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add the columns to IsCorrect\n",
    "# IsCorrect['total_answered'] = ''\n",
    "# IsCorrect['prop_correct'] = ''\n",
    "# IsCorrect['CMA'] = ''\n",
    "# IsCorrect['total_q_answered'] = ''\n",
    "# IsCorrect['lvl2'] = ''\n",
    "# IsCorrect['CMA_correct_subject'] = ''\n",
    "# IsCorrect['holiday'] = ''\n",
    "# IsCorrect['unique_day                                                                                                                                    '] = ''\n",
    "# IsCorrect['yr2'] = ''\n",
    "# IsCorrect['age'] = ''\n",
    "# IsCorrect['term'] = ''\n",
    "# IsCorrect['time'] = ''\n",
    "# IsCorrect['is_weekend'] = ''\n",
    "# IsCorrect['last_answered'] = ''\n",
    "# IsCorrect['repeat'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b71d70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf91e035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad32506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79e8956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6719bd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f1c746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30eaf94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "82e4d6dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-d1627927bc2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0munique_student_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'unique_day'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_student_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0munique_student_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'UserId'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0munique_student_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DateAnswered'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[0mtrain_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_student_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inner'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'UserId'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0munique_student_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1142\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1144\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1145\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getbool_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[0minds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3623\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3624\u001b[0m         \"\"\"\n\u001b[1;32m-> 3625\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3626\u001b[0m         \u001b[1;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3627\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3610\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3612\u001b[1;33m         new_data = self._mgr.take(\n\u001b[0m\u001b[0;32m   3613\u001b[0m             \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3614\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m         return self.reindex_indexer(\n\u001b[0m\u001b[0;32m    859\u001b[0m             \u001b[0mnew_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice)\u001b[0m\n\u001b[0;32m    671\u001b[0m             )\n\u001b[0;32m    672\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m             new_blocks = [\n\u001b[0m\u001b[0;32m    674\u001b[0m                 blk.take_nd(\n\u001b[0;32m    675\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             new_blocks = [\n\u001b[1;32m--> 674\u001b[1;33m                 blk.take_nd(\n\u001b[0m\u001b[0;32m    675\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m                     \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1510\u001b[0m         \u001b[1;31m# but are passed the axis depending on the calling routing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1511\u001b[0m         \u001b[1;31m# if its REALLY axis 0, then this will be a reindex and not a take\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1512\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1514\u001b[0m         \u001b[1;31m# Called from three places in managers, all of which satisfy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\sparse\\array.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, allow_fill, fill_value)\u001b[0m\n\u001b[0;32m    880\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_fill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\sparse\\array.py\u001b[0m in \u001b[0;36m_take_with_fill\u001b[1;34m(self, indices, fill_value)\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[1;31m# 1.) we took for an index of -1 (new)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m         \u001b[1;31m# 2.) we took a value that was self.fill_value (old)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m         \u001b[0msp_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msp_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlookup_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m         \u001b[0mnew_fill_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m         \u001b[0mold_fill_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msp_indexer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0mnew_fill_indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 'total_answered',\n",
    "#         train_set['total_answered'] = train_set.groupby(['UserId'])['IsCorrect'].transform('count')\n",
    "\n",
    "#         # 'prop_correct',\n",
    "#         train_set['total_correct'] = train_set.groupby(['UserId'])['IsCorrect'].transform('sum')\n",
    "#         train_set['prop_correct'] = train_set['total_correct'] / train_set['total_answered']\n",
    "# #         train_set.drop('total_correct', inplace=True)\n",
    "                \n",
    "#         # CMA\n",
    "#         train_set.sort_values(['UserId', 'DateAnswered'], inplace=True)\n",
    "#         CMA = train_set.groupby(['UserId']).IsCorrect.expanding().mean()\n",
    "#         train_set['CMA'] = CMA.reset_index(level=0, drop=True)\n",
    "        \n",
    "#         # 'total_q_answered',\n",
    "#         train_set['total_q_answered'] = train_set.groupby(['QuestionId'])['QuestionId'].transform('count')\n",
    "\n",
    "# # lvl2 - needs SubjectId first\n",
    "# train_set['lvl2'] = 0\n",
    "# for i in [' 101', ' 1156', ' 119', ' 149', ' 151', ' 32', ' 49', ' 692', ' 71']:\n",
    "#     if i in train_set.columns.tolist():\n",
    "#         i_int = (int(i[1:]))\n",
    "#         train_set['lvl2'] = train_set['lvl2'] + (train_set[i] * i_int)\n",
    "        \n",
    "# # CMA_correct_subject - need lvl2 first\n",
    "# CMA_correct_subject = train_set.groupby(['UserId', 'lvl2']).IsCorrect.expanding().mean()\n",
    "# train_set['CMA_correct_subject'] = CMA_correct_subject.reset_index(level=[0,1], drop=True)\n",
    "\n",
    "# # 'holiday',\n",
    "# train_set['holiday'] = 1\n",
    "# train_set.loc[((train_set['DateAnswered'] < '2018-10-20') & (train_set['DateAnswered'] > '2018-09-03')) |\n",
    "#       ((train_set['DateAnswered'] > '2018-10-28') & (train_set['DateAnswered'] < '2018-12-20')) |\n",
    "#       ((train_set['DateAnswered'] > '2019-01-02') & (train_set['DateAnswered'] < '2019-02-16')) |\n",
    "#       ((train_set['DateAnswered'] > '2019-02-24') & (train_set['DateAnswered'] < '2019-04-06')) |\n",
    "#       ((train_set['DateAnswered'] > '2019-04-22') & (train_set['DateAnswered'] < '2019-05-25')) |\n",
    "#       ((train_set['DateAnswered'] > '2019-06-02') & (train_set['DateAnswered'] < '2019-07-25')) |\n",
    "\n",
    "#       ((train_set['DateAnswered'] > '2019-09-01') & (train_set['DateAnswered'] < '2019-10-19')) |\n",
    "#       ((train_set['DateAnswered'] > '2019-10-27') & (train_set['DateAnswered'] < '2019-12-20')) |\n",
    "#       ((train_set['DateAnswered'] > '2020-01-05') & (train_set['DateAnswered'] < '2020-02-15')) |\n",
    "#       ((train_set['DateAnswered'] > '2020-02-23') & (train_set['DateAnswered'] < '2020-04-03')) |\n",
    "#       ((train_set['DateAnswered'] > '2020-04-19') & (train_set['DateAnswered'] < '2020-05-23')) |\n",
    "#       ((train_set['DateAnswered'] > '2020-05-31') & (train_set['DateAnswered'] < '2020-07-23')) \n",
    "#       ,'holiday'] = 0\n",
    "\n",
    "# 'unique_day',\n",
    "unique_student_train = pd.DataFrame(data=train_set['UserId'].unique(), columns=['UserId'])\n",
    "unique_student_train['unique_day'] = 0\n",
    "for i in range(len(unique_student_train)):\n",
    "        unique_student_train.iloc[i, 1] =  len(train_set.loc[train_set['UserId']==unique_student_train.iloc[i, 0]]['DateAnswered'].dt.normalize().unique())\n",
    "train_set = train_set.merge(unique_student_train, how='inner', on='UserId')\n",
    "del unique_student_train\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "# 'yr2',\n",
    "train_set['yr2'] = 1\n",
    "train_set.loc[(train_set['DateAnswered'] < '2019-09-01'), 'yr2'] = 0\n",
    "\n",
    "# 'age',\n",
    "train_set['age'] = train_set['DateAnswered'] - train_set['DateOfBirth'] \n",
    "\n",
    "# 'term',\n",
    "train_set['term'] = 6\n",
    "\n",
    "train_set.loc[((train_set['DateAnswered'] >= '2018-09-04') & (train_set['DateAnswered'] < '2018-10-29')) |\n",
    "              ((train_set['DateAnswered'] >= '2019-09-02') & (train_set['DateAnswered'] < '2019-10-28')),\n",
    "              'term'] = 1\n",
    "\n",
    "train_set.loc[((train_set['DateAnswered'] >= '2018-10-29') & (train_set['DateAnswered'] < '2019-01-03')) |\n",
    "              ((train_set['DateAnswered'] >= '2019-10-28') & (train_set['DateAnswered'] < '2020-01-06')),\n",
    "              'term'] = 2\n",
    "\n",
    "train_set.loc[((train_set['DateAnswered'] >= '2019-01-03') & (train_set['DateAnswered'] < '2019-02-25')) |\n",
    "              ((train_set['DateAnswered'] >= '2020-01-06') & (train_set['DateAnswered'] < '2020-02-24')),\n",
    "              'term'] = 3\n",
    "\n",
    "train_set.loc[((train_set['DateAnswered'] >= '2019-02-25') & (train_set['DateAnswered'] < '2019-04-23')) |\n",
    "              ((train_set['DateAnswered'] >= '2020-02-24') & (train_set['DateAnswered'] < '2020-04-20')),\n",
    "              'term'] = 4\n",
    "\n",
    "train_set.loc[((train_set['DateAnswered'] >= '2019-04-23') & (train_set['DateAnswered'] < '2019-06-03')) |\n",
    "              ((train_set['DateAnswered'] >= '2020-04-20') & (train_set['DateAnswered'] < '2020-06-01')),\n",
    "              'term'] = 5\n",
    "\n",
    "# 'time',\n",
    "train_set['time'] = 4\n",
    "train_set.loc[(train_set['DateAnswered'].dt.strftime(\"%H:%M:%S\") >= '08:00:00') &\n",
    "              (train_set['DateAnswered'].dt.strftime(\"%H:%M:%S\") < '12:00:00')\n",
    "               , 'time'] = 1\n",
    "\n",
    "train_set.loc[(train_set['DateAnswered'].dt.strftime(\"%H:%M:%S\") >= '12:00:00') &\n",
    "              (train_set['DateAnswered'].dt.strftime(\"%H:%M:%S\") < '16:00:00')\n",
    "               , 'time'] = 2\n",
    "\n",
    "train_set.loc[(train_set['DateAnswered'].dt.strftime(\"%H:%M:%S\") >= '16:00:00') &\n",
    "              (train_set['DateAnswered'].dt.strftime(\"%H:%M:%S\") < '20:00:00')\n",
    "               , 'time'] = 3\n",
    "\n",
    "# 'is_weekend',\n",
    "train_set['is_weekend'] = 0\n",
    "train_set.loc[train_set['DateAnswered'].dt.dayofweek > 4, 'is_weekend'] = 1\n",
    "\n",
    "# 'last_answered', adds repeat as well\n",
    "train_set.sort_values(['UserId', 'DateAnswered'], inplace=True)\n",
    "train_set['last_answered'] = train_set['DateAnswered'] - datetime.datetime.strptime('2018-09-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "train_set['repeat'] = (train_set['UserId']==train_set['UserId'].shift(1))\n",
    "train_set.loc[train_set['repeat'] == True, 'last_answered'] = train_set['DateAnswered'].diff() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32e30c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: lvl 2 book pg 59\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(m_training, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbbb537f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# based on: https://github.com/ageron/handson-ml2/blob/master/02_end_to_end_machine_learning_project.ipynb\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self): # no *args or **kargs\n",
    "    def fit(self, train_set, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, train_set):\n",
    "        \n",
    "        # 'total_answered',\n",
    "        train_set['total_answered'] = train_set.groupby(['UserId'])['IsCorrect'].transform('count')\n",
    "\n",
    "        # 'prop_correct',\n",
    "        train_set['total_correct'] = train_set.groupby(['UserId'])['IsCorrect'].transform('sum')\n",
    "        train_set['prop_correct'] = train_set['total_correct'] / train_set['total_answered']\n",
    "#         train_set.drop('total_correct', inplace=True)\n",
    "\n",
    "        # CMA\n",
    "        train_set.sort_values(['UserId', 'DateAnswered'], inplace=True)\n",
    "        CMA = train_set.groupby(['UserId']).IsCorrect.expanding().mean()\n",
    "        train_set['CMA'] = CMA.reset_index(level=0, drop=True)\n",
    "\n",
    "        # 'total_q_answered',\n",
    "        train_set['total_q_answered'] = train_set.groupby(['QuestionId'])['QuestionId'].transform('count')\n",
    "\n",
    "        # lvl2 - needs SubjectId first\n",
    "        train_set['lvl2'] = 0\n",
    "        for i in [' 101', ' 1156', ' 119', ' 149', ' 151', ' 32', ' 49', ' 692', ' 71']:\n",
    "            if i in train_set.columns.tolist():\n",
    "                i_int = (int(i[1:]))\n",
    "                train_set['lvl2'] = train_set['lvl2'] + (train_set[i] * i_int)\n",
    "\n",
    "        # CMA_correct_subject - need lvl2 first\n",
    "        CMA_correct_subject = train_set.groupby(['UserId', 'lvl2']).IsCorrect.expanding().mean()\n",
    "        train_set['CMA_correct_subject'] = CMA_correct_subject.reset_index(level=[0,1], drop=True)\n",
    "\n",
    "        # 'holiday',\n",
    "        train_set['holiday'] = 1\n",
    "        train_set.loc[((train_set['DateAnswered'] < '2018-10-20') & (train_set['DateAnswered'] > '2018-09-03')) |\n",
    "              ((train_set['DateAnswered'] > '2018-10-28') & (train_set['DateAnswered'] < '2018-12-20')) |\n",
    "              ((train_set['DateAnswered'] > '2019-01-02') & (train_set['DateAnswered'] < '2019-02-16')) |\n",
    "              ((train_set['DateAnswered'] > '2019-02-24') & (train_set['DateAnswered'] < '2019-04-06')) |\n",
    "              ((train_set['DateAnswered'] > '2019-04-22') & (train_set['DateAnswered'] < '2019-05-25')) |\n",
    "              ((train_set['DateAnswered'] > '2019-06-02') & (train_set['DateAnswered'] < '2019-07-25')) |\n",
    "\n",
    "              ((train_set['DateAnswered'] > '2019-09-01') & (train_set['DateAnswered'] < '2019-10-19')) |\n",
    "              ((train_set['DateAnswered'] > '2019-10-27') & (train_set['DateAnswered'] < '2019-12-20')) |\n",
    "              ((train_set['DateAnswered'] > '2020-01-05') & (train_set['DateAnswered'] < '2020-02-15')) |\n",
    "              ((train_set['DateAnswered'] > '2020-02-23') & (train_set['DateAnswered'] < '2020-04-03')) |\n",
    "              ((train_set['DateAnswered'] > '2020-04-19') & (train_set['DateAnswered'] < '2020-05-23')) |\n",
    "              ((train_set['DateAnswered'] > '2020-05-31') & (train_set['DateAnswered'] < '2020-07-23')) \n",
    "              ,'holiday'] = 0\n",
    "\n",
    "        train_set['help'] = 0\n",
    "        \n",
    "        # 'unique_day',\n",
    "        unique_student_train = pd.DataFrame(data=train_set['UserId'].unique(), columns=['UserId'])\n",
    "        unique_student_train['unique_day'] = 0\n",
    "        for i in range(len(unique_student_train)):\n",
    "                unique_student_train.iloc[i, 1] =  len(train_set.loc[train_set['UserId']==unique_student_train.iloc[i, 0]]['DateAnswered'].dt.normalize().unique())\n",
    "        train_set = train_set.merge(unique_student_train, how='inner', on='UserId')\n",
    "        del unique_student_train\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "        # 'yr2',\n",
    "        train_set['yr2'] = 1\n",
    "        train_set.loc[(train_set['DateAnswered'] < '2019-09-01'), 'yr2'] = 0\n",
    "\n",
    "        # 'age',\n",
    "        train_set['age'] = train_set['DateAnswered'] - train_set['DateOfBirth'] \n",
    "\n",
    "        # 'term',\n",
    "        train_set['term'] = 6\n",
    "\n",
    "        train_set.loc[((train_set['DateAnswered'] >= '2018-09-04') & (train_set['DateAnswered'] < '2018-10-29')) |\n",
    "                      ((train_set['DateAnswered'] >= '2019-09-02') & (train_set['DateAnswered'] < '2019-10-28')),\n",
    "                      'term'] = 1\n",
    "\n",
    "        train_set.loc[((train_set['DateAnswered'] >= '2018-10-29') & (train_set['DateAnswered'] < '2019-01-03')) |\n",
    "                      ((train_set['DateAnswered'] >= '2019-10-28') & (train_set['DateAnswered'] < '2020-01-06')),\n",
    "                      'term'] = 2\n",
    "\n",
    "        train_set.loc[((train_set['DateAnswered'] >= '2019-01-03') & (train_set['DateAnswered'] < '2019-02-25')) |\n",
    "                      ((train_set['DateAnswered'] >= '2020-01-06') & (train_set['DateAnswered'] < '2020-02-24')),\n",
    "                      'term'] = 3\n",
    "\n",
    "        train_set.loc[((train_set['DateAnswered'] >= '2019-02-25') & (train_set['DateAnswered'] < '2019-04-23')) |\n",
    "                      ((train_set['DateAnswered'] >= '2020-02-24') & (train_set['DateAnswered'] < '2020-04-20')),\n",
    "                      'term'] = 4\n",
    "\n",
    "        train_set.loc[((train_set['DateAnswered'] >= '2019-04-23') & (train_set['DateAnswered'] < '2019-06-03')) |\n",
    "                      ((train_set['DateAnswered'] >= '2020-04-20') & (train_set['DateAnswered'] < '2020-06-01')),\n",
    "                      'term'] = 5\n",
    "\n",
    "        # 'time',\n",
    "        train_set['time'] = 4\n",
    "        train_set.loc[(train_set['DateAnswered'].dt.strftime(\"%H:%M:%S\") >= '08:00:00') &\n",
    "                      (train_set['DateAnswered'].dt.strftime(\"%H:%M:%S\") < '12:00:00')\n",
    "                       , 'time'] = 1\n",
    "\n",
    "        train_set.loc[(train_set['DateAnswered'].dt.strftime(\"%H:%M:%S\") >= '12:00:00') &\n",
    "                      (train_set['DateAnswered'].dt.strftime(\"%H:%M:%S\") < '16:00:00')\n",
    "                       , 'time'] = 2\n",
    "\n",
    "        train_set.loc[(train_set['DateAnswered'].dt.strftime(\"%H:%M:%S\") >= '16:00:00') &\n",
    "                      (train_set['DateAnswered'].dt.strftime(\"%H:%M:%S\") < '20:00:00')\n",
    "                       , 'time'] = 3\n",
    "\n",
    "        # 'is_weekend',\n",
    "        train_set['is_weekend'] = 0\n",
    "        train_set.loc[train_set['DateAnswered'].dt.dayofweek > 4, 'is_weekend'] = 1\n",
    "\n",
    "        # 'last_answered', adds repeat as well\n",
    "        train_set.sort_values(['UserId', 'DateAnswered'], inplace=True)\n",
    "        train_set['last_answered'] = train_set['DateAnswered'] - datetime.datetime.strptime('2018-09-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "        train_set['repeat'] = (train_set['UserId']==train_set['UserId'].shift(1))\n",
    "        train_set.loc[train_set['repeat'] == True, 'last_answered'] = train_set['DateAnswered'].diff()\n",
    "        \n",
    "        return train_set\n",
    "\n",
    "attr_adder = CombinedAttributesAdder()\n",
    "# training_extra_attribs = attr_adder.transform(train_set)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
